# opt
本文为各种优化方法的总结和理解，以及各方法的python简易实现
# 无约束优化方法
    梯度类算法
          梯度下降法Gradient Descent
          随机梯度类SGD
          小批量梯度下降 (Mini-batch Gradient Descent)
          动量梯度下降（Momentum Gradient Descent）
          Nesterov 加速梯度（Nesterov Accelerated Gradient, NAG）
          Adam
    次梯度算法
    牛顿类算法(Newton Method)
          经典牛顿法算法
          修正牛顿法（带线搜索）
            SR1更新
            BFGS更新
# 有约束优化方法
    综述
    外点罚函数法
    内点罚函数法
    增广拉格朗日函数法
    KKT条件
